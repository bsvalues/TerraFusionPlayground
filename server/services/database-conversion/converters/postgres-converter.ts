/**
 * PostgreSQL Database Converter
 *
 * This converter handles migrations with PostgreSQL as the target database.
 * It can convert from various source databases to PostgreSQL.
 */

import { BaseConverter } from './base-converter';
import { LLMService } from '../../llm-service';
import {
  SchemaAnalysisResult,
  DatabaseConnectionConfig,
  MigrationPlan,
  MigrationOptions,
  MigrationResult,
  ValidationResult,
  TableMapping,
  TableDefinition,
} from '../types';

/**
 * Converter for PostgreSQL as target database
 */
export class PostgresConverter extends BaseConverter {
  private dataTypeMapping: Record<string, string> | null = null;

  constructor(llmService: LLMService) {
    super(llmService);
  }

  /**
   * Generate a migration plan for converting to PostgreSQL
   */
  async generateMigrationPlan(
    schemaAnalysis: SchemaAnalysisResult,
    targetConfig: DatabaseConnectionConfig,
    customInstructions?: string
  ): Promise<MigrationPlan> {
    console.log('Generating PostgreSQL migration plan...');

    // Ensure we have a data type mapping
    if (!this.dataTypeMapping) {
      this.dataTypeMapping = await this.getDataTypeMapping();
    }

    // Create table mappings
    const tableMappings: TableMapping[] = [];

    for (const sourceTable of schemaAnalysis.tables) {
      // Generate column mappings
      const columnMappings = sourceTable.columns.map(col => ({
        sourceColumn: col.name,
        targetColumn: col.name,
        transformation: this.getColumnTransformation(
          col.name,
          col.dataType,
          schemaAnalysis.databaseType
        ),
      }));

      // Create table mapping
      tableMappings.push({
        sourceTable: sourceTable.schema
          ? `${sourceTable.schema}.${sourceTable.name}`
          : sourceTable.name,
        targetTable: targetConfig.schema
          ? `${targetConfig.schema}.${sourceTable.name}`
          : sourceTable.name,
        columnMappings,
        skip: false,
      });
    }

    // Generate view mappings if views exist in schema analysis
    const viewMappings = schemaAnalysis.views.map(view => ({
      sourceView: view.schema ? `${view.schema}.${view.name}` : view.name,
      targetView: targetConfig.schema ? `${targetConfig.schema}.${view.name}` : view.name,
      rewrittenDefinition: this.convertViewDefinition(view.definition, schemaAnalysis.databaseType),
      skip: false,
    }));

    // Generate procedure mappings if procedures exist in schema analysis
    const procedureMappings = schemaAnalysis.procedures?.map(proc => ({
      sourceProcedure: proc.schema ? `${proc.schema}.${proc.name}` : proc.name,
      targetProcedure: targetConfig.schema ? `${targetConfig.schema}.${proc.name}` : proc.name,
      rewrittenDefinition: this.convertProcedureDefinition(
        proc.definition,
        schemaAnalysis.databaseType
      ),
      skip: false,
    }));

    // Generate trigger mappings if triggers exist in schema analysis
    const triggerMappings = schemaAnalysis.triggers?.map(trigger => ({
      sourceTrigger: trigger.schema ? `${trigger.schema}.${trigger.name}` : trigger.name,
      targetTrigger: targetConfig.schema ? `${targetConfig.schema}.${trigger.name}` : trigger.name,
      rewrittenDefinition: this.convertTriggerDefinition(
        trigger.definition,
        schemaAnalysis.databaseType
      ),
      skip: false,
    }));

    // If custom instructions are provided, use AI to refine the migration plan
    if (customInstructions) {
      return this.refineWithAI(
        schemaAnalysis,
        {
          tableMappings,
          viewMappings,
          procedureMappings,
          triggerMappings,
          createdAt: new Date(),
        },
        customInstructions
      );
    }

    // Create the migration plan
    const migrationPlan: MigrationPlan = {
      tableMappings,
      viewMappings,
      procedureMappings,
      triggerMappings,
      createdAt: new Date(),
    };

    return migrationPlan;
  }

  /**
   * Generate migration SQL script
   */
  async generateMigrationScript(
    migrationPlan: MigrationPlan,
    targetConfig: DatabaseConnectionConfig
  ): Promise<string> {
    console.log('Generating PostgreSQL migration script...');

    const schemaName = targetConfig.schema || 'public';

    // Start building the script
    let script = `-- PostgreSQL Migration Script\n`;
    script += `-- Generated on ${new Date().toISOString()}\n\n`;

    // Create schema if not default
    if (schemaName !== 'public') {
      script += `-- Create schema\n`;
      script += `CREATE SCHEMA IF NOT EXISTS ${schemaName};\n\n`;
    }

    // Generate table creation
    script += `-- Create tables\n`;

    for (const mapping of migrationPlan.tableMappings) {
      if (mapping.skip) continue;

      const tableName = mapping.targetTable;

      script += `CREATE TABLE IF NOT EXISTS ${tableName} (\n`;

      // Add columns
      const columnDefs = mapping.columnMappings.map(col => {
        // This is simplified and would need enhancement for real scenarios
        return `  ${col.targetColumn} TEXT`;
      });

      script += columnDefs.join(',\n');
      script += `\n);\n\n`;
    }

    // Generate view creation
    if (migrationPlan.viewMappings && migrationPlan.viewMappings.length > 0) {
      script += `-- Create views\n`;

      for (const viewMapping of migrationPlan.viewMappings) {
        if (viewMapping.skip) continue;

        if (viewMapping.rewrittenDefinition) {
          script += viewMapping.rewrittenDefinition;
        } else {
          script += `CREATE OR REPLACE VIEW ${viewMapping.targetView} AS\n`;
          script += `  SELECT * FROM some_table; -- Placeholder - actual definition would be generated\n`;
        }

        script += `\n`;
      }
    }

    // Generate procedure creation
    if (migrationPlan.procedureMappings && migrationPlan.procedureMappings.length > 0) {
      script += `-- Create functions/procedures\n`;

      for (const procMapping of migrationPlan.procedureMappings) {
        if (procMapping.skip) continue;

        if (procMapping.rewrittenDefinition) {
          script += procMapping.rewrittenDefinition;
        } else {
          script += `CREATE OR REPLACE FUNCTION ${procMapping.targetProcedure}() RETURNS void AS $$\n`;
          script += `BEGIN\n`;
          script += `  -- Placeholder - actual function body would be generated\n`;
          script += `END;\n`;
          script += `$$ LANGUAGE plpgsql;\n`;
        }

        script += `\n`;
      }
    }

    // Generate trigger creation
    if (migrationPlan.triggerMappings && migrationPlan.triggerMappings.length > 0) {
      script += `-- Create triggers\n`;

      for (const triggerMapping of migrationPlan.triggerMappings) {
        if (triggerMapping.skip) continue;

        if (triggerMapping.rewrittenDefinition) {
          script += triggerMapping.rewrittenDefinition;
        } else {
          script += `-- Placeholder for trigger ${triggerMapping.targetTrigger}\n`;
        }

        script += `\n`;
      }
    }

    // Add data migration statements
    script += `-- Data migration\n`;

    for (const mapping of migrationPlan.tableMappings) {
      if (mapping.skip) continue;

      const sourceTable = mapping.sourceTable;
      const targetTable = mapping.targetTable;

      const sourceColumns = mapping.columnMappings.map(m => m.sourceColumn).join(', ');
      const targetColumns = mapping.columnMappings.map(m => m.targetColumn).join(', ');

      script += `-- Migrate data from ${sourceTable} to ${targetTable}\n`;
      script += `INSERT INTO ${targetTable} (${targetColumns})\n`;
      script += `SELECT ${sourceColumns} FROM ${sourceTable}`;

      if (mapping.filterCondition) {
        script += ` WHERE ${mapping.filterCondition}`;
      }

      script += `;\n\n`;
    }

    // Add post-migration statements
    script += `-- Post-migration\n`;

    // Add any preMigrationScripts
    if (migrationPlan.preMigrationScripts) {
      script =
        `-- Pre-migration custom scripts\n` +
        migrationPlan.preMigrationScripts.join('\n\n') +
        `\n\n` +
        script;
    }

    // Add any postMigrationScripts
    if (migrationPlan.postMigrationScripts) {
      script +=
        `\n-- Post-migration custom scripts\n` + migrationPlan.postMigrationScripts.join('\n\n');
    }

    return script;
  }

  /**
   * Execute the migration
   */
  async executeMigration(
    sourceConfig: DatabaseConnectionConfig,
    targetConfig: DatabaseConnectionConfig,
    migrationPlan: MigrationPlan,
    options: MigrationOptions = {}
  ): Promise<MigrationResult> {
    console.log('Executing PostgreSQL migration...');

    // This would connect to both databases and perform the migration
    // For this implementation, we'll delegate to the DataMigrationService

    // Placeholder implementation
    const result: MigrationResult = {
      success: true,
      startTime: new Date(),
      endTime: new Date(),
      tableResults: migrationPlan.tableMappings
        .filter(t => !t.skip)
        .map(t => ({
          tableName: t.targetTable,
          rowsProcessed: 0,
          success: true,
        })),
      totalRowsProcessed: 0,
      warnings: [],
      log: ['Migration execution is delegated to DataMigrationService'],
    };

    return result;
  }

  /**
   * Validate the migration
   */
  async validateMigration(
    sourceConfig: DatabaseConnectionConfig,
    targetConfig: DatabaseConnectionConfig,
    migrationPlan: MigrationPlan,
    migrationResult: MigrationResult
  ): Promise<ValidationResult> {
    console.log('Validating PostgreSQL migration...');

    // This would connect to both databases and validate the migration
    // For now, this is a placeholder

    const result: ValidationResult = {
      success: true,
      tableValidations: migrationPlan.tableMappings
        .filter(t => !t.skip)
        .map(t => ({
          tableName: t.targetTable,
          sourceRowCount: 0,
          targetRowCount: 0,
          countMatch: true,
          dataSamplesMatch: true,
          issues: [],
        })),
      issues: [],
      report: 'Migration validation completed successfully. All tables validated.',
    };

    return result;
  }

  /**
   * Get data type mapping from source type to PostgreSQL
   */
  async getDataTypeMapping(): Promise<Record<string, string>> {
    // If we already have a mapping, return it
    if (this.dataTypeMapping) {
      return this.dataTypeMapping;
    }

    // Otherwise, get it from AI or use default
    return this.getDefaultDataTypeMapping('any', 'postgresql');
  }

  /**
   * Generate DDL for creating tables
   */
  async generateTablesDDL(
    schemaAnalysis: SchemaAnalysisResult,
    migrationPlan: MigrationPlan
  ): Promise<string> {
    let ddl = '';

    // Add schema creation if needed
    const schemaNames = new Set<string>();
    for (const mapping of migrationPlan.tableMappings) {
      if (mapping.skip) continue;

      const parts = mapping.targetTable.split('.');
      if (parts.length > 1) {
        schemaNames.add(parts[0]);
      }
    }

    // Add CREATE SCHEMA statements
    for (const schema of schemaNames) {
      if (schema !== 'public') {
        ddl += `CREATE SCHEMA IF NOT EXISTS ${schema};\n`;
      }
    }

    if (schemaNames.size > 0) {
      ddl += '\n';
    }

    // Find matching source table for each mapping
    for (const mapping of migrationPlan.tableMappings) {
      if (mapping.skip) continue;

      // Find the source table definition
      const sourceTableName = mapping.sourceTable.split('.').pop();
      const sourceTable = schemaAnalysis.tables.find(t => t.name === sourceTableName);

      if (!sourceTable) {
        ddl += `-- Source table not found for ${mapping.sourceTable}\n\n`;
        continue;
      }

      // Create the table
      ddl += `CREATE TABLE ${mapping.targetTable} (\n`;

      // Add columns
      const columnDefs = [];

      for (const colMapping of mapping.columnMappings) {
        const sourceCol = sourceTable.columns.find(c => c.name === colMapping.sourceColumn);

        if (sourceCol) {
          // Get PostgreSQL data type
          const pgType = this.mapDataType(sourceCol.dataType, schemaAnalysis.databaseType);

          let colDef = `  ${colMapping.targetColumn} ${pgType}`;

          // Add nullable constraint
          if (!sourceCol.isNullable) {
            colDef += ' NOT NULL';
          }

          // Add default value if present
          if (sourceCol.defaultValue && !sourceCol.isIdentity) {
            colDef += ` DEFAULT ${this.convertDefaultValue(sourceCol.defaultValue)}`;
          }

          // Add identity column
          if (sourceCol.isIdentity) {
            if (pgType.toLowerCase().includes('int')) {
              colDef += ' GENERATED ALWAYS AS IDENTITY';
            } else {
              // For non-integer types, use a sequence
              colDef += ` DEFAULT nextval('${mapping.targetTable}_${colMapping.targetColumn}_seq'::regclass)`;

              // Add a note about creating the sequence
              ddl =
                `-- Create sequence for ${mapping.targetTable}.${colMapping.targetColumn}\n` +
                `CREATE SEQUENCE IF NOT EXISTS ${mapping.targetTable}_${colMapping.targetColumn}_seq;\n\n` +
                ddl;
            }
          }

          columnDefs.push(colDef);
        }
      }

      // Add primary key
      if (sourceTable.primaryKey) {
        const pkColumns = sourceTable.primaryKey.columns.map(col => {
          // Find the target column name for this source column
          const mapping = mapping.columnMappings.find(m => m.sourceColumn === col);
          return mapping ? mapping.targetColumn : col;
        });

        if (pkColumns.length > 0) {
          columnDefs.push(`  PRIMARY KEY (${pkColumns.join(', ')})`);
        }
      }

      ddl += columnDefs.join(',\n');
      ddl += '\n);\n\n';

      // Add comments
      ddl += `COMMENT ON TABLE ${mapping.targetTable} IS 'Migrated from ${mapping.sourceTable}';\n`;

      for (const colMapping of mapping.columnMappings) {
        const sourceCol = sourceTable.columns.find(c => c.name === colMapping.sourceColumn);

        if (sourceCol) {
          ddl += `COMMENT ON COLUMN ${mapping.targetTable}.${colMapping.targetColumn} IS 'Migrated from ${mapping.sourceTable}.${colMapping.sourceColumn}';\n`;
        }
      }

      ddl += '\n';
    }

    return ddl;
  }

  /**
   * Generate DDL for creating indexes
   */
  async generateIndexesDDL(
    schemaAnalysis: SchemaAnalysisResult,
    migrationPlan: MigrationPlan
  ): Promise<string> {
    let ddl = '';

    // Find matching source table for each mapping
    for (const mapping of migrationPlan.tableMappings) {
      if (mapping.skip) continue;

      // Find the source table definition
      const sourceTableName = mapping.sourceTable.split('.').pop();
      const sourceTable = schemaAnalysis.tables.find(t => t.name === sourceTableName);

      if (!sourceTable || !sourceTable.indexes || sourceTable.indexes.length === 0) {
        continue;
      }

      // Add indexes
      for (const idx of sourceTable.indexes) {
        // Map source column names to target column names
        const targetColumns = idx.columns.map(col => {
          const colMapping = mapping.columnMappings.find(m => m.sourceColumn === col);
          return colMapping ? colMapping.targetColumn : col;
        });

        // Create index name (ensuring uniqueness)
        const targetTableName = mapping.targetTable.split('.').pop();
        const idxName = `idx_${targetTableName}_${targetColumns.join('_')}`;

        // Create the index
        ddl += `CREATE ${idx.isUnique ? 'UNIQUE ' : ''}INDEX ${idxName} ON ${mapping.targetTable} `;

        // Add index type if specified
        if (idx.type && idx.type !== 'btree') {
          ddl += `USING ${idx.type} `;
        }

        ddl += `(${targetColumns.join(', ')});\n`;
      }

      if (sourceTable.indexes.length > 0) {
        ddl += '\n';
      }
    }

    return ddl;
  }

  /**
   * Generate DDL for creating foreign keys
   */
  async generateForeignKeysDDL(
    schemaAnalysis: SchemaAnalysisResult,
    migrationPlan: MigrationPlan
  ): Promise<string> {
    let ddl = '';

    // Find matching source table for each mapping
    for (const mapping of migrationPlan.tableMappings) {
      if (mapping.skip) continue;

      // Find the source table definition
      const sourceTableName = mapping.sourceTable.split('.').pop();
      const sourceTable = schemaAnalysis.tables.find(t => t.name === sourceTableName);

      if (!sourceTable || !sourceTable.foreignKeys || sourceTable.foreignKeys.length === 0) {
        continue;
      }

      // Add foreign keys
      for (const fk of sourceTable.foreignKeys) {
        // Get the target table mapping for the referenced table
        const referencedTableName = fk.referencedTable.split('.').pop();
        const referencedTableMapping = migrationPlan.tableMappings.find(m => {
          const sourceTable = m.sourceTable.split('.').pop();
          return sourceTable === referencedTableName && !m.skip;
        });

        if (!referencedTableMapping) {
          ddl += `-- Referenced table not found for foreign key from ${mapping.targetTable} to ${fk.referencedTable}\n`;
          continue;
        }

        // Map source column names to target column names
        const sourceColumns = fk.columns.map(col => {
          const colMapping = mapping.columnMappings.find(m => m.sourceColumn === col);
          return colMapping ? colMapping.targetColumn : col;
        });

        // Map referenced column names to target column names
        const referencedColumns = fk.referencedColumns.map(col => {
          const colMapping = referencedTableMapping.columnMappings.find(
            m => m.sourceColumn === col
          );
          return colMapping ? colMapping.targetColumn : col;
        });

        // Create constraint name
        const targetTableName = mapping.targetTable.split('.').pop();
        const refTableName = referencedTableMapping.targetTable.split('.').pop();
        const fkName = `fk_${targetTableName}_${refTableName}`;

        // Create the foreign key
        ddl += `ALTER TABLE ${mapping.targetTable} ADD CONSTRAINT ${fkName} `;
        ddl += `FOREIGN KEY (${sourceColumns.join(', ')}) `;
        ddl += `REFERENCES ${referencedTableMapping.targetTable} (${referencedColumns.join(', ')})`;

        // Add ON DELETE clause if specified
        if (fk.onDelete) {
          ddl += ` ON DELETE ${fk.onDelete}`;
        }

        // Add ON UPDATE clause if specified
        if (fk.onUpdate) {
          ddl += ` ON UPDATE ${fk.onUpdate}`;
        }

        ddl += `;\n`;
      }

      if (sourceTable.foreignKeys.length > 0) {
        ddl += '\n';
      }
    }

    return ddl;
  }

  /**
   * Generate DML for migrating data
   */
  async generateDataMigrationDML(
    schemaAnalysis: SchemaAnalysisResult,
    migrationPlan: MigrationPlan
  ): Promise<string> {
    let dml = '';

    // Generate data migration statements for each table
    for (const mapping of migrationPlan.tableMappings) {
      if (mapping.skip) continue;

      const sourceColumns = mapping.columnMappings
        .map(m => {
          if (m.transformation) {
            return `${m.transformation} AS ${m.sourceColumn}`;
          }
          return m.sourceColumn;
        })
        .join(', ');

      const targetColumns = mapping.columnMappings.map(m => m.targetColumn).join(', ');

      dml += `-- Migrate data from ${mapping.sourceTable} to ${mapping.targetTable}\n`;
      dml += `INSERT INTO ${mapping.targetTable} (${targetColumns})\n`;
      dml += `SELECT ${sourceColumns} FROM ${mapping.sourceTable}`;

      // Add filter condition if specified
      if (mapping.filterCondition) {
        dml += `\nWHERE ${mapping.filterCondition}`;
      }

      dml += `;\n\n`;
    }

    return dml;
  }

  /**
   * Convert stored procedures
   */
  async convertStoredProcedures(
    schemaAnalysis: SchemaAnalysisResult,
    migrationPlan: MigrationPlan
  ): Promise<string> {
    if (!schemaAnalysis.procedures || schemaAnalysis.procedures.length === 0) {
      return '-- No procedures to convert\n';
    }

    let sql = '';

    // Handle procedure mappings if present
    if (migrationPlan.procedureMappings) {
      for (const procMapping of migrationPlan.procedureMappings) {
        if (procMapping.skip) continue;

        // If we have a rewritten definition, use it
        if (procMapping.rewrittenDefinition) {
          sql += procMapping.rewrittenDefinition;
          sql += '\n\n';
          continue;
        }

        // Otherwise, find the source procedure
        const sourceProcName = procMapping.sourceProcedure.split('.').pop();
        const sourceProc = schemaAnalysis.procedures.find(p => p.name === sourceProcName);

        if (!sourceProc) {
          sql += `-- Source procedure not found for ${procMapping.sourceProcedure}\n\n`;
          continue;
        }

        // Try to convert the procedure
        sql += `-- Converting procedure ${procMapping.sourceProcedure} to ${procMapping.targetProcedure}\n`;

        // For SQL Server, MySQL, etc. to PostgreSQL, delegate to AI for complex conversion
        if (schemaAnalysis.databaseType !== 'postgresql') {
          sql += `-- TODO: Convert from ${schemaAnalysis.databaseType} to PostgreSQL\n`;
          sql += `-- Original definition:\n`;
          sql += `/*\n${sourceProc.definition}\n*/\n\n`;

          // Use AI for conversion for complex procedures
          sql += await this.convertProcedureWithAI(sourceProc, schemaAnalysis.databaseType);
        } else {
          // For PostgreSQL to PostgreSQL, just copy the definition with updated schema
          sql += sourceProc.definition;
          sql += '\n\n';
        }
      }
    }

    return sql;
  }

  /**
   * Convert triggers
   */
  async convertTriggers(
    schemaAnalysis: SchemaAnalysisResult,
    migrationPlan: MigrationPlan
  ): Promise<string> {
    if (!schemaAnalysis.triggers || schemaAnalysis.triggers.length === 0) {
      return '-- No triggers to convert\n';
    }

    let sql = '';

    // Handle trigger mappings if present
    if (migrationPlan.triggerMappings) {
      for (const triggerMapping of migrationPlan.triggerMappings) {
        if (triggerMapping.skip) continue;

        // If we have a rewritten definition, use it
        if (triggerMapping.rewrittenDefinition) {
          sql += triggerMapping.rewrittenDefinition;
          sql += '\n\n';
          continue;
        }

        // Otherwise, find the source trigger
        const sourceTriggerName = triggerMapping.sourceTrigger.split('.').pop();
        const sourceTrigger = schemaAnalysis.triggers.find(t => t.name === sourceTriggerName);

        if (!sourceTrigger) {
          sql += `-- Source trigger not found for ${triggerMapping.sourceTrigger}\n\n`;
          continue;
        }

        // Try to convert the trigger
        sql += `-- Converting trigger ${triggerMapping.sourceTrigger} to ${triggerMapping.targetTrigger}\n`;

        // For SQL Server, MySQL, etc. to PostgreSQL, delegate to AI for complex conversion
        if (schemaAnalysis.databaseType !== 'postgresql') {
          sql += `-- TODO: Convert from ${schemaAnalysis.databaseType} to PostgreSQL\n`;
          sql += `-- Original definition:\n`;
          sql += `/*\n${sourceTrigger.definition}\n*/\n\n`;

          // Use AI for conversion for complex triggers
          sql += await this.convertTriggerWithAI(sourceTrigger, schemaAnalysis.databaseType);
        } else {
          // For PostgreSQL to PostgreSQL, just copy the definition with updated schema
          sql += sourceTrigger.definition;
          sql += '\n\n';
        }
      }
    }

    return sql;
  }

  /**
   * Convert a view definition from another database type to PostgreSQL
   */
  private convertViewDefinition(definition: string, sourceType: string): string {
    // For PostgreSQL to PostgreSQL, no conversion needed
    if (sourceType === 'postgresql') {
      return definition;
    }

    // For other databases, this would be implemented with specific conversion rules
    // For now, return a placeholder
    return `-- Original ${sourceType} view definition:\n-- ${definition.replace(/\n/g, '\n-- ')}\n\n-- TODO: Convert to PostgreSQL syntax`;
  }

  /**
   * Convert a procedure definition from another database type to PostgreSQL
   */
  private convertProcedureDefinition(definition: string, sourceType: string): string {
    // For PostgreSQL to PostgreSQL, no conversion needed
    if (sourceType === 'postgresql') {
      return definition;
    }

    // For other databases, this would be implemented with specific conversion rules
    // For now, return a placeholder
    return `-- Original ${sourceType} procedure definition:\n-- ${definition.replace(/\n/g, '\n-- ')}\n\n-- TODO: Convert to PostgreSQL syntax`;
  }

  /**
   * Convert a trigger definition from another database type to PostgreSQL
   */
  private convertTriggerDefinition(definition: string, sourceType: string): string {
    // For PostgreSQL to PostgreSQL, no conversion needed
    if (sourceType === 'postgresql') {
      return definition;
    }

    // For other databases, this would be implemented with specific conversion rules
    // For now, return a placeholder
    return `-- Original ${sourceType} trigger definition:\n-- ${definition.replace(/\n/g, '\n-- ')}\n\n-- TODO: Convert to PostgreSQL syntax`;
  }

  /**
   * Map a data type from another database type to PostgreSQL
   */
  private mapDataType(sourceType: string, sourceDatabaseType: string): string {
    // For exact mappings, look in the mapping
    const mappedType = this.dataTypeMapping?.[sourceType.toLowerCase()];
    if (mappedType) {
      return mappedType;
    }

    // For approximate mappings, try to match based on common type patterns
    const typeLC = sourceType.toLowerCase();

    // String types
    if (typeLC.includes('char') || typeLC.includes('string') || typeLC.includes('text')) {
      if (typeLC.includes('var')) {
        return 'character varying';
      }
      if (typeLC.includes('text')) {
        return 'text';
      }
      return 'character';
    }

    // Numeric types
    if (typeLC.includes('int')) {
      if (typeLC.includes('big')) {
        return 'bigint';
      }
      if (typeLC.includes('small')) {
        return 'smallint';
      }
      if (typeLC.includes('tiny')) {
        return 'smallint';
      }
      return 'integer';
    }

    if (typeLC.includes('decimal') || typeLC.includes('numeric')) {
      return 'numeric';
    }

    if (typeLC.includes('float') || typeLC.includes('double')) {
      return 'double precision';
    }

    if (typeLC.includes('real')) {
      return 'real';
    }

    // Boolean type
    if (typeLC.includes('bool')) {
      return 'boolean';
    }

    // Date/time types
    if (typeLC.includes('date')) {
      if (typeLC.includes('time')) {
        return 'timestamp';
      }
      return 'date';
    }

    if (typeLC.includes('time')) {
      if (typeLC.includes('zone')) {
        return 'timestamp with time zone';
      }
      return 'time';
    }

    // Binary types
    if (typeLC.includes('binary') || typeLC.includes('blob')) {
      return 'bytea';
    }

    // JSON types
    if (typeLC.includes('json')) {
      return 'jsonb';
    }

    // XML type
    if (typeLC.includes('xml')) {
      return 'xml';
    }

    // UUID type
    if (typeLC.includes('uuid')) {
      return 'uuid';
    }

    // Default to text for unknown types
    console.warn(
      `Unknown data type: ${sourceType} from ${sourceDatabaseType}, using TEXT as default`
    );
    return 'text';
  }

  /**
   * Get a SQL transformation for a column based on its type
   */
  private getColumnTransformation(
    columnName: string,
    dataType: string,
    sourceDatabaseType: string
  ): string | undefined {
    // For most direct mappings, no transformation needed
    if (sourceDatabaseType === 'postgresql') {
      return undefined;
    }

    const typeLC = dataType.toLowerCase();

    // Some types may need special handling
    if (sourceDatabaseType === 'sqlserver') {
      // Convert SQL Server datetime to PostgreSQL timestamp
      if (typeLC.includes('datetime')) {
        return `CAST(${columnName} AS timestamp)`;
      }

      // Convert SQL Server uniqueidentifier to PostgreSQL uuid
      if (typeLC.includes('uniqueidentifier')) {
        return `CAST(${columnName} AS uuid)`;
      }
    }

    if (sourceDatabaseType === 'mysql') {
      // Convert MySQL datetime to PostgreSQL timestamp
      if (typeLC.includes('datetime')) {
        return `CAST(${columnName} AS timestamp)`;
      }

      // Convert MySQL tinyint(1) to PostgreSQL boolean
      if (typeLC === 'tinyint(1)') {
        return `CAST(${columnName} AS boolean)`;
      }
    }

    if (sourceDatabaseType === 'oracle') {
      // Convert Oracle DATE to PostgreSQL timestamp
      if (typeLC === 'date') {
        return `CAST(${columnName} AS timestamp)`;
      }

      // Convert Oracle CLOB to PostgreSQL text
      if (typeLC === 'clob') {
        return `CAST(${columnName} AS text)`;
      }

      // Convert Oracle BLOB to PostgreSQL bytea
      if (typeLC === 'blob') {
        return `CAST(${columnName} AS bytea)`;
      }
    }

    // No special transformation needed
    return undefined;
  }

  /**
   * Convert a default value from another database to PostgreSQL syntax
   */
  private convertDefaultValue(defaultValue: string): string {
    // Handle NULL
    if (defaultValue === null || defaultValue.toLowerCase() === 'null') {
      return 'NULL';
    }

    // Handle functions
    if (defaultValue.toLowerCase().includes('current_timestamp')) {
      return 'CURRENT_TIMESTAMP';
    }

    if (defaultValue.toLowerCase().includes('getdate()')) {
      return 'CURRENT_TIMESTAMP';
    }

    if (defaultValue.toLowerCase().includes('newid()')) {
      return 'gen_random_uuid()';
    }

    // Handle literals
    if (defaultValue.match(/^'.*'$/)) {
      // Already a string literal
      return defaultValue;
    }

    if (defaultValue.match(/^-?\d+$/)) {
      // Integer literal
      return defaultValue;
    }

    if (defaultValue.match(/^-?\d+\.\d+$/)) {
      // Decimal literal
      return defaultValue;
    }

    // Default to wrapping in quotes
    return `'${defaultValue.replace(/'/g, "''")}'`;
  }

  /**
   * Use AI to convert a stored procedure from another database type to PostgreSQL
   */
  private async convertProcedureWithAI(
    procedure: any,
    sourceDatabaseType: string
  ): Promise<string> {
    const prompt = `
      Please convert the following ${sourceDatabaseType} stored procedure to PostgreSQL:
      
      Procedure name: ${procedure.name}
      Parameters: ${JSON.stringify(procedure.parameters)}
      Return type: ${procedure.returnType || 'void'}
      Is function: ${procedure.isFunction}
      
      Original definition:
      ${procedure.definition}
      
      Convert this to a PostgreSQL function with proper syntax and semantics.
      Use the PostgreSQL PL/pgSQL language.
      Return ONLY the converted PostgreSQL function code, no explanations.
    `;

    const response = await this.llmService.generateText(prompt);

    // Make sure it's a valid function
    if (
      !response.toLowerCase().includes('create') &&
      !response.toLowerCase().includes('function')
    ) {
      return `-- AI conversion failed for procedure ${procedure.name}\n-- Please convert manually\n\n`;
    }

    return response;
  }

  /**
   * Use AI to convert a trigger from another database type to PostgreSQL
   */
  private async convertTriggerWithAI(trigger: any, sourceDatabaseType: string): Promise<string> {
    const prompt = `
      Please convert the following ${sourceDatabaseType} trigger to PostgreSQL:
      
      Trigger name: ${trigger.name}
      Table name: ${trigger.tableName}
      Events: ${trigger.events.join(', ')}
      Timing: ${trigger.timing}
      Is row-level: ${trigger.isRowLevel}
      
      Original definition:
      ${trigger.definition}
      
      Convert this to a PostgreSQL trigger with proper syntax and semantics.
      Remember that PostgreSQL triggers require a function to be defined first, then the trigger references the function.
      Return ONLY the converted PostgreSQL trigger code, including both the function and trigger creation, no explanations.
    `;

    const response = await this.llmService.generateText(prompt);

    // Make sure it's a valid trigger
    if (!response.toLowerCase().includes('create') && !response.toLowerCase().includes('trigger')) {
      return `-- AI conversion failed for trigger ${trigger.name}\n-- Please convert manually\n\n`;
    }

    return response;
  }

  /**
   * Refine a migration plan using AI
   */
  private async refineWithAI(
    schemaAnalysis: SchemaAnalysisResult,
    migrationPlan: MigrationPlan,
    customInstructions: string
  ): Promise<MigrationPlan> {
    const sourceType = schemaAnalysis.databaseType;

    // Build the prompt
    const prompt = `
      I have a migration plan from ${sourceType} to PostgreSQL. 
      I need to refine it based on these custom instructions:
      
      "${customInstructions}"
      
      Here is the current migration plan:
      ${JSON.stringify(migrationPlan, null, 2)}
      
      And here is information about the source schema:
      Database type: ${sourceType}
      Tables: ${schemaAnalysis.tables.length}
      Views: ${schemaAnalysis.views.length}
      Procedures: ${schemaAnalysis.procedures?.length || 0}
      Triggers: ${schemaAnalysis.triggers?.length || 0}
      
      Please update the migration plan according to the custom instructions.
      Return ONLY the updated migration plan as valid JSON.
    `;

    const response = await this.llmService.generateText(prompt);

    try {
      // Extract JSON from the response
      const jsonMatch = response.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        console.error('No JSON object found in AI response');
        return migrationPlan;
      }

      const updatedPlan = JSON.parse(jsonMatch[0]);

      // Add notes from AI
      updatedPlan.notes = `Migration plan refined by AI based on custom instructions: "${customInstructions}"`;
      updatedPlan.modifiedAt = new Date();

      return updatedPlan;
    } catch (error) {
      console.error('Error parsing AI refined migration plan:', error);
      console.log('AI response:', response);

      // Return the original plan
      return migrationPlan;
    }
  }
}
